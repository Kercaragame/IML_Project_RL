default_settings: null
behaviors:
  BasiqueAgentAdvanced:
    # Configuration de l'entrainement
    init_path: null
    keep_checkpoints: 5
    checkpoint_interval: 500000
    max_steps: 1000000
    time_horizon: 64
    summary_freq: 10000
    threaded: false
    trainer_type: ppo

    hyperparameters:
      # Hyperparametres communs à tous les trainer
      batch_size: 1024
      buffer_size: 10240
      learning_rate: 0.00003
      learning_rate_schedule: linear

      # Hyperparametres spécifique à PPO
      beta: 0.005
      beta_schedule: linear
      epsilon: 0.2
      epsilon_schedule: linear
      lambd: 0.95
      num_epoch: 3
      shared_critic: false

    # Configuration du réseau de neuronne
    network_settings:
      normalize: false
      hidden_units: 128
      num_layers: 2
      vis_encode_type: simple
      conditioning_type: none

      # Ajout de la mémoire
      memory: null

    reward_signals:
      # Récompense d'environnement
      extrinsic:
        gamma: 0.99
        strength: 1.0

    # Option comportement inutilisé dans ce projet
    behavioral_cloning: null
    self_play: null
